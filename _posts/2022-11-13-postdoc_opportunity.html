---
permalink: /postdoct_job_description_2022
---

<!DOCTYPE html>
<html lang="en">
    <head>
    <title>SMC Lab | Job Openings</title>
    </head>
  {% include head.html %}

  <body>
  {% include nav_sub.html %}
  <section class="bg-faded" id="Postdoc_Job_description_2022">
    <div class="container">
        <div class="row"><p class="h1"></p></div>
        
        <div class="col-lg-12 text-center">
            <h2 class="section-heading">Job Description for Postdoc Research Fellows</h2>
            <hr class="primary">
        </div>

        <p class='text-justify'>The Research Fellows (RFs) will engage in research and development of an AI-Lyricist system and Singing and Listening to Improve Our Natural Speaking (SLIONS) system for language learning and/or speech rehabilitation. The RFs will work in a multi-disciplinary team to help develop 1) machine learning algorithms, 2) an automatic lyrics generation system, and 3) an automatic singing voice/speech evaluation system. The RFs will help coordinate research activities and supervise research staff/students in the team, and perform data analyses. The RFs will need to be capable of working both independently and in a team, of developing innovative solutions, and of publishing research findings in high-impact conferences and journals. These positions are part of two 3-year projects from the Ministry of Education (MOE) of Singapore with a value of SGD2.4 millions (ca. USD1.75 millions).</p>

        <p class='text-justify'><b>Here are the relevant references for the projects:</b></p>
        <ul>
            <li><p>Wang, Y. (2019). <a href="archive/pdf/2019-2021/2019_YeWang_abstract_Dagstuhl_Jan2019.pdf" target="_blank">Singing Voice Modelling for Language Learning</a>, Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik.</p></li>

            <li><p>Murad, D., Wang, R., Turnbull, D., &amp; Wang, Y. (2018). <a href="archive/pdf/2017-2018/2018_ACMMM18_PaperID1029.pdf" target="_blank">SLIONS: A Karaoke Application to Enhance Foreign Language Learning</a>, in <em>2018 ACM International Conference on Multimedia (MM'18)</em>, pp. 1679-1687. [<a href="https://www.comp.nus.edu.sg/news/features/2018-slions-wang-ye/" target="_blank" style="color:#031d83;">NUS News</a>]</p></li>

            <li><p>Ma, X., Wang, Y., Kan, M. Y., and Lee, W. S., (2021). <a href="archive/pdf/2019-2021/2021_AI-lyricist.pdf" target="_blank">AI-Lyricist: Generating Music and Vocabulary Constrained Lyrics</a>, in <em>2021 ACM International Conference on Multimedia (MM'21)</em>, pp. 1002-1011.</p></li>

            <li><p>Sharma, B., &amp; Wang, Y. (2020). <a href="archive/pdf/2019-2021/2019_SingingIntelligibility.pdf" target="_blank">Automatic Evaluation of Song Intelligibility using Singing Adapted STOI and Vocal-specific Features</a>,&nbsp;<em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, vo.28, pp. 319-331. [<a href="https://github.com/bidishasharma/Automatic-Song-Intelligibility" target="_blank" style="color:#031d83;">code</a>] [<a href="https://drive.google.com/file/d/1CafkGMV1wrDDXme69HoU0qPuAJSohkNN/view?usp=sharing" target="_blank" style="color:#031d83;">data</a>]</p></li>

            <li><p class="text-align">Gu, X.*, Ou, L.*, Ong, D., and Wang, Y., (2022). <a href="archive/pdf/2022_ACM_MM_MM-ALT.pdf" target="_blank">MM-ALT: A Multimodal Automatic Lyric Transcription System</a>, in <em>2022 ACM International Conference on Multimedia (MM'22)</em>, pp. 3328-3337. [<a href="https://n20em.github.io/" target="_blank" style="color:#031d83;">demo</a>]</p></li>

            <li><p class="text-align">Ou, L.*, Gu, X.*, and Wang, Y., (2022). <a href="archive/pdf/2022_ALT_ISMIR_2022_Camera_ready 8.23.pdf" target="_blank">Transfer Learning of wav2vec 2.0 for Automatic Lyric Transcription</a>, in <em>Proceedings of the 23rd International Society for Music Information Retrieval Conference (<b>ISMIR 2022</b>)</em>.</p></li>

            <li><p class="text-align">Wei, W., Huang, H., Gu, X., Wang, H., and Wang, Y., (2022 December). <a href="archive/pdf/2022_TMLR_camera_ready.pdf" target="_blank">Unsupervised Mismatch Localization in Cross-Modal Sequential Data with Application to Mispronunciations Localization</a>. <em>Transactions on Machine Learning Research</em> (12/2022).</p></li>

        </ul>


        <p class='text-justify'><b>Candidates will need:</b></p>

        <ul>
            <li><p>Ph.D. in Computer Science & Engineering, Electrical Engineering, or related disciplines</p></li>
            <li><p>Experience in signal processing and machine learning or natural language processing is required</p></li>
            <li><p>Strong analytical and programming skills</p></li>
            <li><p>Strong publication track record</p></li>
            <li><p>Strong ability to work independently and in teams</p></li>
            <li><p>Experience with automatic speech recognition (ASR), automatic lyrics or singing voice generation/analysis is a plus</p></li>
            <li><p>Knowledge of music is a plus</p></li>
        </ul>

        <p class='text-justify'><b>Key details:</b></p>
        <ul>
            <li><p>Positions available immediately</p></li>
            <li><p>1-year contract extendable for 2 years</p></li>
            <li><p>Competitive salary and benefits</p></li>
            <li><p>The candidates must be based in, or be able to relocate to, Singapore</p></li>
         </ul>

         <p class='text-justify'>For enquiries and further details about the responsibilities of the positions, please contact Associate Prof. Ye Wang at <a href="mailto:wangye@comp.nus.edu.sg" target="_blank">wangye@comp.nus.edu.sg</a> with the subject title of "SMC4HHP positions".</p>



        </div>


        
    

</section>
  <footer class="bg-light text-center text-lg-start">
    {% include scripts.html %}
    {% include copyright.html %}
  </footer>
</html>


























